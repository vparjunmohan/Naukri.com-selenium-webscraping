{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By \n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = input('Search Job: ')\n",
    "location = input('Job Location: ')\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "driver = webdriver.Chrome(executable_path=r'C:\\webdrivers\\chromedriver.exe', options=options)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.delete_all_cookies()\n",
    "driver.get(url=f'https://www.naukri.com/{search}-jobs?k={search}&l={location}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = input('Enter CSV file name: ')     # Creating CSV File\n",
    "print()\n",
    "csv_file = open(csv_filename+'.csv', 'a', encoding=\"utf-8\", newline='')  # Opening CSV File\n",
    "\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Header of CSV File\n",
    "csv_writer.writerow(['Job Title', 'Company Name', 'Experience', 'Salary', 'Location', 'Date Posted', 'Job Description', 'Role', 'Industry Type', 'Functional Area', 'Employment Type', 'Role', 'Education', 'Key Skills', 'About Company'])\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    total_pages = driver.find_elements_by_xpath('//*[@class=\"fleft grey-text mr-5 fs12\"]')\n",
    "    for i in total_pages:\n",
    "        page = i.text\n",
    "    print('Scraping: ', page)\n",
    "\n",
    "    \n",
    "    job_titles = driver.find_elements_by_xpath('//*[@class=\"title fw500 ellipsis\"]')\n",
    "    job_links = []                  # List of job links on a particular page\n",
    "    \n",
    "    for title in job_titles:\n",
    "        link = title.get_attribute('href')\n",
    "        job_links.append(link)\n",
    "\n",
    "    page_url = driver.current_url  # URL of the current page\n",
    "    \n",
    "    for link in job_links:         # Scraping individual job link on the particular page\n",
    "\n",
    "        driver.get(link)\n",
    "\n",
    "        titles = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[1]/header/h1')\n",
    "        for title in titles:\n",
    "            a = title.text             # Job title\n",
    "\n",
    "        names = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[1]/div/a[1]')\n",
    "        for name in names:\n",
    "            b = name.text              # Company Name\n",
    "\n",
    "        experiences = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[1]/span')\n",
    "        for experience in experiences:\n",
    "            c = experience.text        # Year of Experience\n",
    "\n",
    "        salaries = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[2]/span')\n",
    "        for salary in salaries:\n",
    "            d = salary.text            # Salary\n",
    "\n",
    "        locations = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[1]/div[2]/div[3]/span')\n",
    "        for location in locations:\n",
    "            e = location.text          # Job location\n",
    "\n",
    "        dates = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[1]/div[2]/div[1]/span[1]/span')\n",
    "        for date in dates:\n",
    "            f = date.text              # Posted Date\n",
    "\n",
    "        descriptions = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[1]')\n",
    "        for description in descriptions:\n",
    "            g = description.text       # Job Description\n",
    "\n",
    "        roles = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[2]/div[1]/span')\n",
    "        for role in roles:\n",
    "            h = role.text              # Job Role  \n",
    "\n",
    "        industry_types = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[3]/div[2]/span')\n",
    "        for industry_type in industry_types:\n",
    "            i = industry_type.text     # Industry Type\n",
    "\n",
    "        functional_areas = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[2]/div[3]')\n",
    "        for functional_area in functional_areas:\n",
    "            j = functional_area.text   # Functional Area\n",
    "\n",
    "        employment_types = driver.find_elements(By.XPATH, 'html/body/div[1]/main/div[2]/div[2]/section[2]/div[2]/div[4]/span')\n",
    "        for employment_type in employment_types:\n",
    "            k = employment_type.text   # Employement Type\n",
    "\n",
    "        role_categories = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[2]/div[5]/span')\n",
    "        for role_category in role_categories:\n",
    "            l = role_category.text     # Role Category\n",
    "\n",
    "\n",
    "        educations = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[3]')\n",
    "        for education in educations:\n",
    "            m = education.text         # Education\n",
    "\n",
    "        skills = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[2]/div[4]')\n",
    "        for skill in skills:\n",
    "            n = skill.text             # Skills\n",
    "\n",
    "        company_details = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div[2]/div[2]/section[4]')\n",
    "        for company_detail in company_details:\n",
    "            o = company_detail.text    # About Company\n",
    "\n",
    "            \n",
    "            csv_writer.writerow([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o])  # Writing all the scrapped data into CSV file.\n",
    "    \n",
    "    driver.get(page_url)           # Redirecting back to particular search result URL\n",
    "    del job_links                  # Deleting the job_links list of previous page\n",
    "    sleep(8)\n",
    "    try:\n",
    "        next_page = driver.find_element_by_xpath('//*[@class=\"fright fs14 btn-secondary br2\"]')\n",
    "        next_page.click()          # Button click for the next page\n",
    "        sleep(8)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    page_url = driver.current_url  # URl of the currently opened page\n",
    "    \n",
    "    print('New Page URL: ', page_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting CSV file to a dataframe\n",
    "df = pd.read_csv(\"yourFileName.csv\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Total number of rows (includes duplicate rows)\n",
    "print(len(list(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicate rows  \n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "# print(df)\n",
    "# print(len(list(df)))\n",
    "\n",
    "\n",
    "output_filename = input('Enter output filename: ')\n",
    "\n",
    "# Writing the results to a different file\n",
    "df.to_csv(output_filename+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
